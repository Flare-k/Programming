{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sex']=train['Sex'].map({'female':0,'male':1})\n",
    "test['Sex']=test['Sex'].map({'female':0,'male':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['email_type']=train['email_type'].map({'gmail':0,\n",
    "                                            'naver':1,\n",
    "                                            'other':2,\n",
    "                                            'nate':3,\n",
    "                                            'hanmail':4})\n",
    "test['email_type']=test['email_type'].map({'gmail':0,\n",
    "                                            'naver':1,\n",
    "                                            'other':2,\n",
    "                                            'nate':3,\n",
    "                                            'hanmail':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person_id', 'Sex', 'past_login_total', 'past_1_month_login',\n",
       "       'past_1_week_login', 'sub_size', 'email_type', 'phone_rat', 'apple_rat',\n",
       "       'login'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var=['Sex', 'past_login_total', 'past_1_month_login',\n",
    "       'past_1_week_login', 'sub_size', 'email_type', 'phone_rat', 'apple_rat']\n",
    "\n",
    "target='login'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=1000, max_features=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=6, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(train[input_var].fillna(0),train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_rf=rf.predict_proba(test[input_var].fillna(0))[:,1]\n",
    "#랜덤포레스트 데이터를 이용하여 test데이터를 예측.\n",
    "#학습은 랜덤포레스트로 시킨 것이다.\n",
    "import xgboost as xgb\n",
    "xgb_param={'objective':'reg:linear',\n",
    "          'metric':'rmse',\n",
    "          'max_depth':6,\n",
    "          'eta':0.03,\n",
    "          'min_child_samples':100}\n",
    "#xgboost로 학습하기 위해."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "folds =KFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:11:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:11:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:11:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:11:36] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "prediction_xgb=np.zeros(len(test))\n",
    "#xgboost로 학습.\n",
    "for fold_, (trn_idx,val_idx) in enumerate(folds.split(train[input_var].values,train[target].values)):\n",
    "    trn_data=xgb.DMatrix(train[input_var].iloc[trn_idx],train[target].iloc[trn_idx])\n",
    "    val_data=xgb.DMatrix(train[input_var].iloc[val_idx],train[target].iloc[val_idx])\n",
    "    \n",
    "    num_tree=10000\n",
    "    \n",
    "    xgb_model=xgb.train(xgb_param,\n",
    "                     trn_data,\n",
    "                     num_tree,\n",
    "                     [(trn_data,'train'),(val_data,'valid')],verbose_eval=0,\n",
    "                     early_stopping_rounds=100)\n",
    "    prediction_xgb+=xgb_model.predict(xgb.DMatrix(test[input_var]),ntree_limit=xgb_model.best_ntree_limit)\n",
    "\n",
    "prediction_xgb=prediction_xgb/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_xgb</th>\n",
       "      <th>pred_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.075344</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.060865</td>\n",
       "      <td>0.004118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048005</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.084458</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067222</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_xgb   pred_rf\n",
       "0  0.075344  0.006000\n",
       "1  0.060865  0.004118\n",
       "2  0.048005  0.000000\n",
       "3  0.084458  0.000000\n",
       "4  0.067222  0.060000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=pd.DataFrame({'pred_xgb':prediction_xgb,'pred_rf':prediction_rf})\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['pred_final'] = final['pred_xgb']/2+final['pred_rf']/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'person_id':test['person_id'], 'login':final['pred_xgb']}).to_csv(\"submission.csv\", index = False)\n",
    "pd.DataFrame({'person_id':test['person_id'], 'login':final['pred_rf']}).to_csv(\"answer_rf.csv\")\n",
    "#pd.DataFrame({'person_id':test['person_id'], 'login':final['pred_final']}).to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 슈퍼모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_xgb</th>\n",
       "      <th>pred_rf</th>\n",
       "      <th>pred_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080118</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.043559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.059709</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.032874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.092629</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.047314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091165</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.084083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_xgb   pred_rf  pred_final\n",
       "0  0.080118  0.007000    0.043559\n",
       "1  0.059709  0.006038    0.032874\n",
       "2  0.050002  0.000000    0.025001\n",
       "3  0.092629  0.002000    0.047314\n",
       "4  0.091165  0.077000    0.084083"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds=KFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_rf=np.zeros(len(train))\n",
    "\n",
    "prediction_rf=np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx,val_idx) in enumerate(folds.split(train[input_var].values,train[target].values)):\n",
    "    rf.fit(train[input_var].iloc[trn_idx].fillna(0),train[target].iloc[trn_idx])\n",
    "    oof_rf[val_idx]=rf.predict_proba(train[input_var].fillna(0).iloc[val_idx])[:,1]\n",
    "    prediction_rf+=rf.predict_proba(test[input_var].fillna(0))[:,1]\n",
    "\n",
    "prediction_rf=prediction_rf/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.00000000e-03, 2.14780741e-02, 0.00000000e+00, 2.80000000e-03,\n",
       "       5.65000000e-02, 3.42720785e-02, 2.72944259e-02, 3.08000000e-02,\n",
       "       8.00000000e-04, 2.20628571e-01, 0.00000000e+00, 4.25708514e-03,\n",
       "       1.91007265e-02, 6.52207846e-04, 7.82985574e-03, 1.91007265e-02,\n",
       "       2.76896186e-03, 5.14633626e-02, 3.21434156e-01, 4.26333333e-02,\n",
       "       5.58748812e-04, 2.18005514e-02, 2.72944259e-02, 1.47200000e-01,\n",
       "       0.00000000e+00, 2.72944259e-02, 1.91007265e-02, 8.58918727e-03,\n",
       "       4.24326667e-01, 5.46647619e-02, 1.00722222e-03, 1.55968254e-03,\n",
       "       1.91007265e-02, 6.21928588e-03, 8.65319865e-05, 4.47071913e-01,\n",
       "       8.30800000e-01, 7.00000000e-03, 0.00000000e+00, 3.13846154e-05,\n",
       "       5.00000000e-03, 8.58918727e-03, 0.00000000e+00, 4.58398900e-01,\n",
       "       7.40800000e-02, 2.76896186e-03, 1.12570000e-01, 1.91007265e-02,\n",
       "       0.00000000e+00, 1.91007265e-02, 9.60509524e-02, 1.09185404e-03,\n",
       "       5.96000000e-01, 8.02367460e-02, 3.24504857e-01, 8.91378490e-02,\n",
       "       1.91007265e-02, 2.72944259e-02, 3.45312809e-02, 0.00000000e+00,\n",
       "       1.55968254e-03, 1.91007265e-02, 4.00000000e-04, 2.72944259e-02,\n",
       "       5.01000000e-01, 0.00000000e+00, 2.72944259e-02, 7.36006276e-02,\n",
       "       0.00000000e+00, 8.56450000e-01, 5.30200000e-02, 1.28939543e-03,\n",
       "       9.37800000e-01, 2.00000000e-04, 3.45312809e-02, 3.00000000e-04,\n",
       "       5.03000000e-01, 2.72944259e-02, 3.42720785e-02, 1.55968254e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.13280714e-01, 1.91007265e-02,\n",
       "       1.87589656e-03, 7.36006276e-02, 3.42720785e-02, 1.45000000e-03,\n",
       "       2.72944259e-02, 3.45312809e-02, 2.72944259e-02, 7.54400000e-01,\n",
       "       1.26816667e-01, 2.42486508e-02, 2.00000000e-04, 1.17088385e-01,\n",
       "       3.26014404e-02, 4.94533333e-02, 2.07569657e-02, 3.45312809e-02,\n",
       "       2.72944259e-02, 4.63612354e-03, 4.00000000e-03, 9.64200000e-01,\n",
       "       0.00000000e+00, 8.25619048e-02, 5.33062222e-01, 5.14633626e-02,\n",
       "       2.07569657e-02, 2.72944259e-02, 1.91007265e-02, 1.91007265e-02,\n",
       "       2.72944259e-02, 1.23860413e-01, 3.13911600e-03, 3.42048005e-01,\n",
       "       3.26014404e-02, 6.52207846e-04, 1.57137889e-02, 7.36006276e-02,\n",
       "       8.40357143e-03, 3.44198501e-03, 9.47800000e-01, 0.00000000e+00,\n",
       "       7.36006276e-02, 2.00000000e-04, 4.52416667e-02, 2.72944259e-02,\n",
       "       2.72944259e-02, 8.21915247e-02, 2.07569657e-02, 1.27493333e-01,\n",
       "       8.58918727e-03, 1.91007265e-02, 9.22466667e-01, 2.90693421e-01,\n",
       "       7.75200000e-02, 3.04000000e-01, 8.91378490e-02, 1.42530962e-01,\n",
       "       8.91378490e-02, 8.65319865e-05, 2.72944259e-02, 8.91378490e-02,\n",
       "       4.61753148e-02, 2.72944259e-02, 8.21915247e-02, 1.69211068e-02,\n",
       "       8.97316032e-01, 0.00000000e+00, 3.45312809e-02, 1.96720000e-01,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.21500000e-02,\n",
       "       0.00000000e+00, 6.20238095e-03, 5.14633626e-02, 9.15000000e-01,\n",
       "       0.00000000e+00, 1.91007265e-02, 1.38873889e-01, 1.11886028e-01,\n",
       "       6.37000000e-03, 0.00000000e+00, 4.82634661e-01, 9.20000000e-03,\n",
       "       1.49268672e-01, 0.00000000e+00, 6.75721429e-02, 2.72944259e-02,\n",
       "       7.30709524e-02, 1.42530962e-01, 4.16453026e-01, 5.01000000e-01,\n",
       "       4.63612354e-03, 0.00000000e+00, 5.14633626e-02, 2.69496392e-03,\n",
       "       3.71000000e-02, 0.00000000e+00, 7.90000000e-02, 0.00000000e+00,\n",
       "       1.17088385e-01, 1.59992906e-01, 1.03137924e-01, 2.69496392e-03,\n",
       "       3.50231947e-01, 1.91007265e-02, 1.93606667e-01, 1.28939543e-03,\n",
       "       2.00000000e-04, 2.72944259e-02, 2.72944259e-02, 7.79333333e-03,\n",
       "       2.72944259e-02, 8.49119048e-02, 3.44198501e-03, 8.72000000e-02,\n",
       "       4.22508413e-01, 6.81220714e-01, 1.56253333e-01, 8.91378490e-02,\n",
       "       7.39736291e-01, 2.18204808e-01, 3.44198501e-03, 1.23860413e-01,\n",
       "       4.61753148e-02, 3.24504857e-01, 0.00000000e+00, 8.91378490e-02,\n",
       "       8.91378490e-02, 6.24120000e-01, 1.08000000e-02, 2.80000000e-03,\n",
       "       3.42720785e-02, 9.56396254e-02, 8.91378490e-02, 1.55968254e-03,\n",
       "       5.58266667e-02, 3.42720785e-02, 3.49739841e-01, 0.00000000e+00,\n",
       "       1.88058288e-03, 5.14633626e-02, 0.00000000e+00, 3.42720785e-02,\n",
       "       7.50080476e-01, 1.87589656e-03, 8.21915247e-02, 4.61753148e-02,\n",
       "       3.42720785e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.68319625e-03, 9.35400000e-02, 1.79390476e-02, 8.00000000e-04,\n",
       "       8.65319865e-05, 2.71295509e-01, 5.10388311e-01, 8.48900000e-01,\n",
       "       1.42530962e-01, 2.68000000e-02, 5.39739261e-03, 0.00000000e+00,\n",
       "       6.52207846e-04, 3.42720785e-02, 1.16210952e-01, 3.42720785e-02,\n",
       "       3.59578835e-02, 5.55875155e-03, 5.14633626e-02, 1.42530962e-01,\n",
       "       1.39916667e-01, 2.72944259e-02, 4.37429313e-01, 1.75729456e-02,\n",
       "       8.57460000e-01, 2.32571429e-02, 3.49739841e-01, 1.70771429e-02,\n",
       "       1.13280714e-01, 3.49739841e-01, 2.68000000e-02, 1.91007265e-02,\n",
       "       2.09933333e-02, 1.75729456e-02, 2.72944259e-02, 1.91007265e-02,\n",
       "       2.00000000e-04, 2.72944259e-02, 7.36006276e-02, 1.09185404e-03,\n",
       "       1.11600000e-01, 6.30000000e-02, 3.10921169e-01, 1.27493333e-01,\n",
       "       1.49268672e-01, 0.00000000e+00, 4.54052153e-02, 0.00000000e+00,\n",
       "       5.14633626e-02, 1.83333333e-04, 3.37291429e-01, 2.07569657e-02,\n",
       "       3.16340069e-02, 2.72944259e-02, 1.91007265e-02, 9.14800000e-01,\n",
       "       7.83328571e-02, 2.36508474e-01, 9.56396254e-02, 9.28600000e-01,\n",
       "       2.29776781e-02, 8.80600000e-01, 5.73700000e-01, 3.38000000e-02,\n",
       "       0.00000000e+00, 1.91007265e-02, 6.31209305e-04, 1.26055823e-01,\n",
       "       0.00000000e+00, 3.45312809e-02, 1.49268672e-01, 4.68333333e-03,\n",
       "       1.32000000e-02, 8.21915247e-02, 8.91378490e-02, 5.94484314e-02,\n",
       "       2.72944259e-02, 2.71861349e-01, 0.00000000e+00, 1.42530962e-01,\n",
       "       1.97719048e-01, 0.00000000e+00, 3.45312809e-02, 4.16600000e-01,\n",
       "       8.91378490e-02, 2.07569657e-02, 1.91007265e-02, 1.11886028e-01,\n",
       "       3.45312809e-02, 2.72944259e-02, 2.72944259e-02, 3.09064762e-01,\n",
       "       3.45312809e-02, 5.75000000e-05, 2.72944259e-02, 8.91378490e-02,\n",
       "       3.87141933e-01, 0.00000000e+00, 4.50000000e-04, 1.91007265e-02,\n",
       "       5.78246766e-01, 3.69900000e-02, 7.95785503e-01, 2.72944259e-02,\n",
       "       5.68333333e-02, 3.45312809e-02, 0.00000000e+00, 7.96000000e-02,\n",
       "       0.00000000e+00, 8.25619048e-02, 2.30000000e-04, 2.72944259e-02,\n",
       "       9.28045977e-03, 7.77787074e-02, 2.00000000e-04, 1.35834936e-01,\n",
       "       4.25829307e-02, 1.91007265e-02, 2.00000000e-04, 0.00000000e+00,\n",
       "       3.29255793e-01, 0.00000000e+00, 4.11300000e-01, 2.72944259e-02,\n",
       "       7.36006276e-02, 8.39803696e-01, 3.42720785e-02, 3.45312809e-02,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.52837698e-01, 7.36006276e-02,\n",
       "       1.82217143e-01, 6.00000000e-04, 3.13911600e-03, 3.42720785e-02,\n",
       "       1.80000000e-03, 0.00000000e+00, 2.58967991e-04, 0.00000000e+00,\n",
       "       8.23341259e-02, 2.07569657e-02, 1.91007265e-02, 4.61753148e-02,\n",
       "       1.94407798e-02, 1.03214113e-01, 2.14780741e-02, 0.00000000e+00,\n",
       "       2.07569657e-02, 2.07569657e-02, 8.91378490e-02, 1.53200000e-01,\n",
       "       0.00000000e+00, 2.72944259e-02, 0.00000000e+00, 3.45312809e-02,\n",
       "       1.73966703e-02, 2.80000000e-03, 1.69885714e-02, 2.07569657e-02,\n",
       "       2.85121473e-02, 8.56342857e-02, 3.10272727e-02, 1.21077914e-01,\n",
       "       1.88058288e-03, 2.95928571e-01, 1.42530962e-01, 8.91378490e-02,\n",
       "       2.02000000e-02, 1.42530962e-01, 0.00000000e+00, 2.41800000e-01,\n",
       "       1.33593724e-03, 7.36006276e-02, 3.91321068e-03, 1.73250000e-01,\n",
       "       1.03214113e-01, 1.91007265e-02, 0.00000000e+00, 2.72944259e-02,\n",
       "       3.92000000e-02, 2.90000000e-03, 0.00000000e+00, 1.27166667e-01,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.00431895e-01, 1.57137889e-02,\n",
       "       0.00000000e+00, 5.78025000e-01, 5.58748812e-04, 6.49866667e-02,\n",
       "       3.42720785e-02, 2.07569657e-02, 4.47071913e-01, 6.77480952e-02,\n",
       "       2.07569657e-02, 2.55266667e-01, 2.72944259e-02, 2.72944259e-02,\n",
       "       1.09185404e-03, 6.15515746e-04, 3.92328571e-01, 8.00000000e-04,\n",
       "       7.46000000e-02, 3.24504857e-01, 1.91007265e-02, 1.03214113e-01,\n",
       "       3.21402584e-01, 3.13846154e-05, 3.42720785e-02, 1.91007265e-02,\n",
       "       4.61753148e-02, 1.91007265e-02, 1.21400000e-01, 5.96000000e-02,\n",
       "       6.96282381e-01, 1.09185404e-03, 8.09533333e-01, 2.93022848e-01,\n",
       "       1.42530962e-01, 1.91007265e-02, 2.72944259e-02, 2.07569657e-02,\n",
       "       1.45000000e-03, 1.73966703e-02, 5.14633626e-02, 2.72944259e-02,\n",
       "       2.72944259e-02, 7.36006276e-02, 1.75891192e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.00000000e-04, 1.91007265e-02, 8.91378490e-02,\n",
       "       2.28987628e-02, 1.91007265e-02, 8.65319865e-05, 1.96653333e-01,\n",
       "       0.00000000e+00, 1.91007265e-02, 2.46052632e-04, 1.31411905e-01,\n",
       "       1.10000000e-03, 8.91378490e-02, 2.72944259e-02, 8.27997619e-02,\n",
       "       1.88058288e-03, 0.00000000e+00, 7.64000000e-02, 6.21928588e-03,\n",
       "       0.00000000e+00, 8.21915247e-02, 4.47071913e-01, 2.23529412e-04,\n",
       "       1.88058288e-03, 1.91007265e-02, 2.72944259e-02, 2.72944259e-02,\n",
       "       1.44000000e-02, 7.36006276e-02, 0.00000000e+00, 2.72944259e-02,\n",
       "       3.42720785e-02, 1.91007265e-02, 1.93606667e-01, 3.97333333e-02,\n",
       "       7.83328571e-02, 1.22336429e-01, 1.69800000e-01, 1.71033333e-02,\n",
       "       4.05940000e-01, 3.30600000e-01, 1.88058288e-03, 1.91007265e-02,\n",
       "       1.91007265e-02, 1.96000000e-02, 1.49992983e-01, 2.07569657e-02,\n",
       "       0.00000000e+00, 5.53593333e-01, 2.72944259e-02, 4.63612354e-03,\n",
       "       3.24504857e-01, 1.91007265e-02, 0.00000000e+00, 1.91007265e-02,\n",
       "       3.24504857e-01, 0.00000000e+00, 1.42530962e-01, 0.00000000e+00,\n",
       "       5.56666667e-03, 2.32571429e-02, 4.59379934e-03, 8.81700000e-01,\n",
       "       0.00000000e+00, 2.47220000e-01, 0.00000000e+00, 5.14633626e-02,\n",
       "       4.83900000e-01, 2.76896186e-03, 1.91007265e-02, 2.92621934e-03,\n",
       "       1.49268672e-01, 5.11442107e-01, 5.14633626e-02, 7.44165507e-02,\n",
       "       2.72944259e-02, 3.21402584e-01, 5.14633626e-02, 6.21928588e-03,\n",
       "       6.21928588e-03, 3.45312809e-02, 2.00000000e-04, 6.15515746e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 7.25166667e-02, 2.32571429e-02,\n",
       "       0.00000000e+00, 7.85859286e-01, 0.00000000e+00, 7.57200000e-01,\n",
       "       5.51269192e-02, 1.91007265e-02, 0.00000000e+00, 6.00000000e-04,\n",
       "       1.68500000e-03, 0.00000000e+00, 2.00000000e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.91007265e-02, 1.84675238e-01,\n",
       "       1.91007265e-02, 1.91007265e-02, 2.56631366e-01, 0.00000000e+00,\n",
       "       1.07716429e-01, 0.00000000e+00, 4.63612354e-03, 3.11355311e-04,\n",
       "       8.65319865e-05, 2.50000000e-04, 0.00000000e+00, 1.91007265e-02,\n",
       "       1.37000000e-01, 9.27900000e-01, 4.45320049e-02, 1.91007265e-02,\n",
       "       3.45312809e-02, 3.19000000e-02, 1.72253333e-01, 1.23860413e-01,\n",
       "       3.42720785e-02, 8.00000000e-03, 3.94908425e-02, 2.12293932e-03,\n",
       "       6.46800000e-01, 2.72944259e-02, 3.24560000e-01, 9.51452381e-03,\n",
       "       7.95785503e-01, 3.93885354e-04, 8.36200000e-01, 1.28939543e-03,\n",
       "       3.59578835e-02, 1.26000000e-02, 3.45312809e-02, 0.00000000e+00,\n",
       "       7.36006276e-02, 1.19508947e-02, 1.19000000e-01, 0.00000000e+00,\n",
       "       4.63612354e-03, 5.01000000e-01, 1.13400000e-01, 2.72944259e-02,\n",
       "       3.13846154e-05, 1.17088385e-01, 3.45312809e-02, 4.66000000e-02,\n",
       "       2.72944259e-02, 2.74000000e-02, 0.00000000e+00, 3.45312809e-02,\n",
       "       9.80933333e-02, 3.01400000e-01, 1.99825238e-01, 0.00000000e+00,\n",
       "       5.42000000e-02, 1.91007265e-02, 7.95785503e-01, 6.32220198e-02,\n",
       "       1.52857143e-03, 2.72944259e-02, 2.07166610e-02, 4.19153771e-01,\n",
       "       2.72944259e-02, 1.17088385e-01, 2.71988123e-02, 9.64272727e-02,\n",
       "       1.88000000e-02, 0.00000000e+00, 8.21133333e-01, 7.95785503e-01,\n",
       "       1.91007265e-02, 1.65800000e-01, 7.36006276e-02, 1.23860413e-01,\n",
       "       2.00000000e-04, 2.72944259e-02, 1.60190476e-03, 2.62000000e-02,\n",
       "       2.00000000e-04, 1.91007265e-02, 2.85121473e-02, 1.42530962e-01,\n",
       "       0.00000000e+00, 5.14633626e-02, 0.00000000e+00, 5.67852383e-03,\n",
       "       3.42720785e-02, 2.72944259e-02, 0.00000000e+00, 4.16453026e-01,\n",
       "       9.40000000e-03, 5.14633626e-02, 7.36006276e-02, 1.91007265e-02,\n",
       "       6.00000000e-04, 1.91007265e-02, 3.13846154e-05, 2.72944259e-02,\n",
       "       0.00000000e+00, 1.14066667e-01, 1.88058288e-03, 3.42048005e-01,\n",
       "       8.84200000e-01, 1.72632877e-03, 7.36006276e-02, 1.78950000e-01,\n",
       "       2.72944259e-02, 0.00000000e+00])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:10:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:10:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:10:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:10:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:10:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "oof_xgb=np.zeros(len(train))\n",
    "\n",
    "prediction_xgb=np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx,val_idx) in enumerate(folds.split(train[input_var].values,train[target].values)):\n",
    "    trn_data=xgb.DMatrix(train[input_var].iloc[trn_idx],train[target].iloc[trn_idx])\n",
    "    val_data=xgb.DMatrix(train[input_var].iloc[val_idx],train[target].iloc[val_idx])\n",
    "    num_tree=10000\n",
    "    xgb_model=xgb.train(xgb_param,\n",
    "                     trn_data,\n",
    "                     num_tree,\n",
    "                     [(trn_data,'train'),(val_data,'valid')],verbose_eval=0,\n",
    "                     early_stopping_rounds=100)\n",
    "    oof_xgb[val_idx]=xgb_model.predict(xgb.DMatrix(train[input_var].iloc[val_idx]),ntree_limit=xgb_model.best_ntree_limit)\n",
    "    prediction_xgb+=xgb_model.predict(xgb.DMatrix(test[input_var]),ntree_limit=xgb_model.best_ntree_limit)\n",
    "prediction_xgb=prediction_xgb/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 2.16661508e-01, 0.00000000e+00, ...,\n",
       "       6.46825397e-04, 8.58250000e-01, 0.00000000e+00])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03582969, 0.04972282, 0.03666085, ..., 0.06444016, 0.96801233,\n",
       "       0.03681806])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oof_rf</th>\n",
       "      <th>oof_xgb</th>\n",
       "      <th>login</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.216662</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.062351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.376271</td>\n",
       "      <td>0.153293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.243838</td>\n",
       "      <td>0.231485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.055523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.029937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012648</td>\n",
       "      <td>0.055108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.345265</td>\n",
       "      <td>0.191293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.056874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.012285</td>\n",
       "      <td>0.041436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.128233</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.081790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.045177</td>\n",
       "      <td>0.026932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.034354</td>\n",
       "      <td>0.042024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.033709</td>\n",
       "      <td>0.071504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.066515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.049129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.092785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.101406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.858000</td>\n",
       "      <td>1.077089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.068752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.169472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.282000</td>\n",
       "      <td>0.042327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.068696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.074312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.027295</td>\n",
       "      <td>0.050223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039706</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>0.138233</td>\n",
       "      <td>0.053081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.055108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.025309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.117101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.018366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.151764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>0.164518</td>\n",
       "      <td>0.054879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>0.134745</td>\n",
       "      <td>0.054765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>0.117000</td>\n",
       "      <td>0.051822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>0.101685</td>\n",
       "      <td>0.173390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.038861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>0.034986</td>\n",
       "      <td>0.087223</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.049549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>0.033646</td>\n",
       "      <td>0.048116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.082911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043317</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>0.090383</td>\n",
       "      <td>0.162918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>0.008330</td>\n",
       "      <td>0.068896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>0.013117</td>\n",
       "      <td>0.041436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>0.023856</td>\n",
       "      <td>0.042507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.047936</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>0.422055</td>\n",
       "      <td>0.409169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.064440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>0.858250</td>\n",
       "      <td>0.968012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        oof_rf   oof_xgb  login\n",
       "0     0.000000  0.035830      0\n",
       "1     0.216662  0.049723      0\n",
       "2     0.000000  0.036661      0\n",
       "3     0.099000  0.062351      0\n",
       "4     0.376271  0.153293      0\n",
       "5     0.000000  0.044466      0\n",
       "6     0.243838  0.231485      0\n",
       "7     0.066000  0.055523      0\n",
       "8     0.002103  0.029937      0\n",
       "9     0.012648  0.055108      0\n",
       "10    0.345265  0.191293      0\n",
       "11    0.004000  0.056874      0\n",
       "12    0.012285  0.041436      0\n",
       "13    0.001943  0.128233      0\n",
       "14    0.047100  0.081790      1\n",
       "15    0.045177  0.026932      0\n",
       "16    0.034354  0.042024      0\n",
       "17    0.033709  0.071504      1\n",
       "18    0.000900  0.066515      0\n",
       "19    0.002565  0.049129      0\n",
       "20    0.061000  0.092785      0\n",
       "21    0.055000  0.101406      0\n",
       "22    0.858000  1.077089      0\n",
       "23    0.090200  0.068752      0\n",
       "24    0.071500  0.169472      1\n",
       "25    0.282000  0.042327      0\n",
       "26    0.094000  0.068696      0\n",
       "27    0.000000  0.058470      0\n",
       "28    0.001000  0.074312      0\n",
       "29    0.027295  0.050223      0\n",
       "...        ...       ...    ...\n",
       "1470  0.000000  0.039706      0\n",
       "1471  0.138233  0.053081      0\n",
       "1472  0.001000  0.055108      0\n",
       "1473  0.000000  0.020848      0\n",
       "1474  0.047000  0.025309      0\n",
       "1475  0.000000  0.036818      0\n",
       "1476  0.143000  0.117101      0\n",
       "1477  0.001250  0.018366      0\n",
       "1478  0.092500  0.151764      0\n",
       "1479  0.164518  0.054879      0\n",
       "1480  0.134745  0.054765      0\n",
       "1481  0.117000  0.051822      0\n",
       "1482  0.101685  0.173390      0\n",
       "1483  0.001000  0.038861      0\n",
       "1484  0.034986  0.087223      1\n",
       "1485  0.000091  0.049549      0\n",
       "1486  0.000000  0.068752      1\n",
       "1487  0.033646  0.048116      0\n",
       "1488  0.150000  0.082911      0\n",
       "1489  0.000000  0.043317      0\n",
       "1490  0.090383  0.162918      0\n",
       "1491  0.008330  0.068896      0\n",
       "1492  0.013117  0.041436      0\n",
       "1493  0.000000  0.047415      0\n",
       "1494  0.023856  0.042507      0\n",
       "1495  0.000118  0.047936      0\n",
       "1496  0.422055  0.409169      0\n",
       "1497  0.000647  0.064440      0\n",
       "1498  0.858250  0.968012      1\n",
       "1499  0.000000  0.036818      0\n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'oof_rf':oof_rf, 'oof_xgb':oof_xgb, 'login':train['login']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_super=pd.DataFrame({'oof_rf':oof_rf,'oof_xgb':oof_xgb,'login':train['login']})\n",
    "test_super=pd.DataFrame({'pred_rf':prediction_rf,'pred_xgb':prediction_xgb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_super[['oof_rf','oof_xgb']], train_super['login'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0420287 , 0.03886684, 0.02739019, 0.04294796, 0.06977512,\n",
       "       0.03703643, 0.03785718, 0.03818014, 0.03152725, 0.16264551,\n",
       "       0.02739019, 0.03709247, 0.03581736, 0.04337318, 0.07294614,\n",
       "       0.03581736, 0.02378929, 0.0428405 , 0.24192657, 0.04788085,\n",
       "       0.02694597, 0.05906235, 0.03785718, 0.08151513, 0.02488004,\n",
       "       0.03785718, 0.03581736, 0.0610514 , 0.25991392, 0.04976745,\n",
       "       0.03177406, 0.03345601, 0.03581736, 0.03616087, 0.0480211 ,\n",
       "       0.34417808, 0.73343475, 0.03819866, 0.03064708, 0.03959819,\n",
       "       0.03485876, 0.0610514 , 0.03064708, 0.39612448, 0.10082979,\n",
       "       0.02378929, 0.07370243, 0.03581736, 0.03060637, 0.03581736,\n",
       "       0.06321636, 0.02088672, 0.4883964 , 0.08207061, 0.26426826,\n",
       "       0.09096965, 0.03581736, 0.03785718, 0.03931503, 0.02739019,\n",
       "       0.03345601, 0.03581736, 0.03197711, 0.03785718, 0.18105465,\n",
       "       0.02663093, 0.03785718, 0.05859356, 0.02280619, 0.68395577,\n",
       "       0.05679389, 0.03500509, 0.80024215, 0.03405196, 0.03931503,\n",
       "       0.03303426, 0.51839231, 0.03785718, 0.03703643, 0.03345601,\n",
       "       0.02663093, 0.02739019, 0.09253289, 0.03581736, 0.0272892 ,\n",
       "       0.05859356, 0.03703643, 0.02697672, 0.03785718, 0.03931503,\n",
       "       0.03785718, 0.65594229, 0.13124726, 0.05876087, 0.03405196,\n",
       "       0.06879983, 0.06279544, 0.05311996, 0.03472324, 0.03931503,\n",
       "       0.03785718, 0.03517225, 0.03456531, 0.81965744, 0.02663093,\n",
       "       0.07008018, 0.44269068, 0.0428405 , 0.03472324, 0.03785718,\n",
       "       0.03581736, 0.03581736, 0.03785718, 0.08895181, 0.02291522,\n",
       "       0.24834299, 0.06279544, 0.04337318, 0.05650821, 0.05859356,\n",
       "       0.03418347, 0.07645067, 0.79186586, 0.03142461, 0.05859356,\n",
       "       0.03088439, 0.05008932, 0.03785718, 0.03785718, 0.10911118,\n",
       "       0.03472324, 0.11447032, 0.0610514 , 0.03581736, 0.79078173,\n",
       "       0.19377953, 0.09393969, 0.25267271, 0.09096965, 0.11466107,\n",
       "       0.09096965, 0.0480211 , 0.03785718, 0.09096965, 0.0480595 ,\n",
       "       0.03785718, 0.10911118, 0.04874231, 0.78368415, 0.03064708,\n",
       "       0.03931503, 0.19258173, 0.02540113, 0.02739019, 0.03064708,\n",
       "       0.03753955, 0.03726346, 0.03684445, 0.0428405 , 0.77934553,\n",
       "       0.02540113, 0.03581736, 0.16641321, 0.18786362, 0.02875434,\n",
       "       0.02663093, 0.22675796, 0.03293002, 0.08202931, 0.02739019,\n",
       "       0.07388196, 0.03785718, 0.0776897 , 0.11466107, 0.3403804 ,\n",
       "       0.18105465, 0.03517225, 0.03726346, 0.0428405 , 0.03059178,\n",
       "       0.04514672, 0.03192755, 0.09470367, 0.02540113, 0.06879983,\n",
       "       0.21479315, 0.11917015, 0.03059178, 0.23891294, 0.03581736,\n",
       "       0.11385559, 0.03500509, 0.03088439, 0.03785718, 0.03785718,\n",
       "       0.04306767, 0.03785718, 0.08278303, 0.07645067, 0.06191065,\n",
       "       0.34384556, 0.57850649, 0.09963995, 0.09096965, 0.46599513,\n",
       "       0.19127811, 0.07645067, 0.08895181, 0.0480595 , 0.26426826,\n",
       "       0.03726346, 0.09096965, 0.09096965, 0.51016284, 0.04961899,\n",
       "       0.02250175, 0.03703643, 0.09210489, 0.09096965, 0.03345601,\n",
       "       0.04710009, 0.03703643, 0.15934403, 0.03726346, 0.03266619,\n",
       "       0.0428405 , 0.02280619, 0.03703643, 0.65497652, 0.0272892 ,\n",
       "       0.10911118, 0.0480595 , 0.03703643, 0.03192755, 0.0263239 ,\n",
       "       0.02663093, 0.0281799 , 0.12343487, 0.02966663, 0.03152725,\n",
       "       0.0480211 , 0.14666936, 0.33942148, 0.70825497, 0.11466107,\n",
       "       0.04225616, 0.03221344, 0.02739019, 0.04337318, 0.03703643,\n",
       "       0.06825086, 0.03703643, 0.04591886, 0.02861657, 0.0428405 ,\n",
       "       0.11466107, 0.113936  , 0.03785718, 0.27743735, 0.03911099,\n",
       "       0.71339895, 0.05698938, 0.15934403, 0.05724211, 0.09253289,\n",
       "       0.15934403, 0.04691323, 0.03581736, 0.0418323 , 0.03911099,\n",
       "       0.03785718, 0.03581736, 0.03405196, 0.03785718, 0.05859356,\n",
       "       0.02088672, 0.0953485 , 0.07739236, 0.17306673, 0.11447032,\n",
       "       0.08202931, 0.03726346, 0.03510888, 0.02722371, 0.0428405 ,\n",
       "       0.03355738, 0.24523916, 0.03472324, 0.04984801, 0.03785718,\n",
       "       0.03581736, 0.81032175, 0.06245023, 0.15751656, 0.09210489,\n",
       "       0.76423726, 0.03373936, 0.73385683, 0.31798506, 0.03871856,\n",
       "       0.02537957, 0.03581736, 0.03178523, 0.17739093, 0.02739019,\n",
       "       0.03931503, 0.08202931, 0.04266871, 0.03505287, 0.10911118,\n",
       "       0.09096965, 0.08632312, 0.03785718, 0.21538394, 0.02739019,\n",
       "       0.11466107, 0.19685447, 0.02663093, 0.03931503, 0.23076948,\n",
       "       0.09096965, 0.03472324, 0.03581736, 0.18786362, 0.03931503,\n",
       "       0.03785718, 0.03785718, 0.15811877, 0.03931503, 0.02590622,\n",
       "       0.03785718, 0.09096965, 0.26284896, 0.02739019, 0.02324428,\n",
       "       0.03581736, 0.50443824, 0.05881131, 0.48176761, 0.03785718,\n",
       "       0.05929839, 0.03931503, 0.03726346, 0.12657129, 0.02739019,\n",
       "       0.07008018, 0.02379274, 0.03785718, 0.02883135, 0.13878701,\n",
       "       0.03088439, 0.07346909, 0.06516097, 0.03581736, 0.03405196,\n",
       "       0.02537957, 0.25932745, 0.03072379, 0.32751128, 0.03785718,\n",
       "       0.05859356, 0.58346192, 0.03703643, 0.03931503, 0.02521956,\n",
       "       0.02739019, 0.5241764 , 0.05859356, 0.14004093, 0.02734031,\n",
       "       0.02291522, 0.03703643, 0.04130892, 0.02280619, 0.03244315,\n",
       "       0.02739019, 0.11636739, 0.03472324, 0.03581736, 0.0480595 ,\n",
       "       0.03957921, 0.10145162, 0.03886684, 0.03060637, 0.03472324,\n",
       "       0.03472324, 0.09096965, 0.1469913 , 0.03387584, 0.03785718,\n",
       "       0.02739019, 0.03931503, 0.03829745, 0.03052747, 0.06438363,\n",
       "       0.03472324, 0.06831491, 0.05802854, 0.08130354, 0.13772714,\n",
       "       0.03266619, 0.27870021, 0.11466107, 0.09096965, 0.0411839 ,\n",
       "       0.11466107, 0.03060637, 0.15243453, 0.03839059, 0.05859356,\n",
       "       0.03269075, 0.12176364, 0.10145162, 0.03581736, 0.02739019,\n",
       "       0.03785718, 0.05271986, 0.04901768, 0.02663093, 0.11490874,\n",
       "       0.02663093, 0.0263239 , 0.06128726, 0.05650821, 0.03726346,\n",
       "       0.51795193, 0.02694597, 0.04650434, 0.03703643, 0.03472324,\n",
       "       0.34417808, 0.07031691, 0.03472324, 0.21600976, 0.03785718,\n",
       "       0.03785718, 0.02088672, 0.03795363, 0.15205018, 0.03152725,\n",
       "       0.06170149, 0.26426826, 0.03581736, 0.10145162, 0.15332546,\n",
       "       0.03959819, 0.03703643, 0.03581736, 0.0480595 , 0.03581736,\n",
       "       0.11992903, 0.05217403, 0.51283265, 0.02088672, 0.71778611,\n",
       "       0.24910503, 0.11466107, 0.03581736, 0.03785718, 0.03472324,\n",
       "       0.02697672, 0.03829745, 0.0428405 , 0.03785718, 0.03785718,\n",
       "       0.05859356, 0.05598719, 0.03726346, 0.03387584, 0.03088439,\n",
       "       0.03581736, 0.09096965, 0.04354126, 0.03581736, 0.0480211 ,\n",
       "       0.18687259, 0.02663093, 0.03581736, 0.02828955, 0.10602413,\n",
       "       0.03549066, 0.09096965, 0.03785718, 0.055902  , 0.03266619,\n",
       "       0.03726346, 0.07756614, 0.03616087, 0.02663093, 0.10911118,\n",
       "       0.34417808, 0.02585998, 0.03266619, 0.03581736, 0.03785718,\n",
       "       0.03785718, 0.03009341, 0.05859356, 0.03387584, 0.03785718,\n",
       "       0.03703643, 0.03581736, 0.11385559, 0.05632769, 0.06245023,\n",
       "       0.07173272, 0.13609533, 0.04908182, 0.32785725, 0.27312709,\n",
       "       0.03266619, 0.03581736, 0.03581736, 0.02767208, 0.22099193,\n",
       "       0.03472324, 0.03726346, 0.49356555, 0.03785718, 0.03517225,\n",
       "       0.26426826, 0.03581736, 0.03192755, 0.03581736, 0.26426826,\n",
       "       0.02663093, 0.11466107, 0.02280619, 0.02917101, 0.05698938,\n",
       "       0.0349895 , 0.73671764, 0.02663093, 0.2061117 , 0.02739019,\n",
       "       0.0428405 , 0.39191409, 0.02378929, 0.03581736, 0.04413816,\n",
       "       0.08202931, 0.35113158, 0.0428405 , 0.07751638, 0.03785718,\n",
       "       0.15332546, 0.0428405 , 0.03616087, 0.03616087, 0.03931503,\n",
       "       0.03177612, 0.03795363, 0.02663093, 0.02663093, 0.06219318,\n",
       "       0.05698938, 0.0263239 , 0.69596611, 0.02521956, 0.69951303,\n",
       "       0.05186186, 0.03581736, 0.02663093, 0.02734031, 0.03671924,\n",
       "       0.02537957, 0.03088439, 0.03060637, 0.03060637, 0.0263239 ,\n",
       "       0.03581736, 0.11458072, 0.03581736, 0.03581736, 0.18570343,\n",
       "       0.02663093, 0.07514006, 0.02488004, 0.03517225, 0.03393979,\n",
       "       0.0480211 , 0.02188656, 0.01919604, 0.03581736, 0.0701628 ,\n",
       "       0.79928793, 0.0411605 , 0.03581736, 0.03931503, 0.04465103,\n",
       "       0.08337034, 0.08895181, 0.03703643, 0.0420287 , 0.06875522,\n",
       "       0.0294234 , 0.54440423, 0.03785718, 0.19223233, 0.03943737,\n",
       "       0.48176761, 0.03159081, 0.72067755, 0.03500509, 0.04591886,\n",
       "       0.04433205, 0.03931503, 0.02663093, 0.05859356, 0.03752183,\n",
       "       0.10220286, 0.03192755, 0.03517225, 0.18105465, 0.13546537,\n",
       "       0.03785718, 0.03959819, 0.06879983, 0.03931503, 0.03917991,\n",
       "       0.03785718, 0.05890938, 0.02663093, 0.03931503, 0.13189405,\n",
       "       0.2675918 , 0.15446177, 0.02488004, 0.04898546, 0.03581736,\n",
       "       0.48176761, 0.08220041, 0.03846587, 0.03785718, 0.0912159 ,\n",
       "       0.28898594, 0.03785718, 0.06879983, 0.04072759, 0.09781585,\n",
       "       0.04093418, 0.0263239 , 0.6135765 , 0.48176761, 0.03581736,\n",
       "       0.12239836, 0.05859356, 0.08895181, 0.03405196, 0.03785718,\n",
       "       0.03027102, 0.04379269, 0.03405196, 0.03581736, 0.06831491,\n",
       "       0.11466107, 0.02739019, 0.0428405 , 0.02739019, 0.03795851,\n",
       "       0.03703643, 0.03785718, 0.03064708, 0.3403804 , 0.03426698,\n",
       "       0.0428405 , 0.05859356, 0.03581736, 0.02790971, 0.03581736,\n",
       "       0.03959819, 0.03785718, 0.0263239 , 0.08952843, 0.03266619,\n",
       "       0.24834299, 0.75739249, 0.02671135, 0.05859356, 0.07759839,\n",
       "       0.03785718, 0.02518309])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(test_super[['pred_rf', 'pred_xgb']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = lr.predict(test_super[['pred_rf', 'pred_xgb']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'person_id':test['person_id'], 'login':final_predictions}).to_csv(\"submission.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
